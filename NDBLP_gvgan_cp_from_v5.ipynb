{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NDBLP_gvgan_cp_from_v4.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KelestZ/HighResImg_Gen/blob/master/NDBLP_gvgan_cp_from_v5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ndnWwxWI4MgX",
        "colab_type": "code",
        "outputId": "f4461df6-eefb-41b1-b34e-8a652ac8f547",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive/')\n",
        "import os    \n",
        "os.chdir(\"/content/gdrive/My Drive/gcn-data/\")\n",
        "!ls\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive/; to attempt to forcibly remount, call drive.mount(\"/content/gdrive/\", force_remount=True).\n",
            "'graph_stat (1).py'   PGG_dblp\t\t     '__pycache__ (1)'\t sub.node.dat\n",
            " graph_stat.py\t      PGG_dblp_version2.zip   sub.label.dat\n",
            " NDBLP\t\t      __pycache__\t      sub.link.dat\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-vdJcKtdpshj",
        "colab_type": "code",
        "outputId": "77c1d1bd-6653-48b1-c8f9-5a1cfb8d43b2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "!pip3 install python-igraph\n",
        "!pip3 install powerlaw"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: python-igraph in /usr/local/lib/python3.6/dist-packages (0.7.1.post6)\n",
            "Requirement already satisfied: powerlaw in /usr/local/lib/python3.6/dist-packages (1.4.6)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from powerlaw) (3.0.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from powerlaw) (1.16.3)\n",
            "Requirement already satisfied: mpmath in /usr/local/lib/python3.6/dist-packages (from powerlaw) (1.1.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from powerlaw) (1.2.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->powerlaw) (2.4.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->powerlaw) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->powerlaw) (1.1.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->powerlaw) (2.5.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from cycler>=0.10->matplotlib->powerlaw) (1.12.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from kiwisolver>=1.0.1->matplotlib->powerlaw) (41.0.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BzuIHriVyBqd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Variable\n",
        "import numpy as np\n",
        "import math\n",
        "from torch.nn.parameter import Parameter\n",
        "from torch.nn.modules.module import Module\n",
        "import numpy as np\n",
        "from sklearn.manifold import SpectralEmbedding\n",
        "import torch.optim as optim\n",
        "import warnings\n",
        "import scipy.sparse as sp\n",
        "from pprint import pprint\n",
        "from graph_stat import *\n",
        "warnings.filterwarnings(\"ignore\")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rT4AhEQQpgOv",
        "colab_type": "code",
        "outputId": "acfd2ea2-d2b9-4677-c2a5-d9126a4ef42f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "a = np.array([\n",
        "    [0, 1, 0],\n",
        "    [1, 0, 0],\n",
        "    [0, 0, 0]\n",
        "])\n",
        "compute_graph_statistics(a)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Values less than or equal to 0 in data. Throwing out 0 or negative values\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'LCC': 2,\n",
              " 'claw_count': 0.0,\n",
              " 'cpl': 1.0,\n",
              " 'd': 0.6666666666666666,\n",
              " 'd_max': 1,\n",
              " 'd_min': 0,\n",
              " 'edge_num': 1,\n",
              " 'gini': -0.33333333333333326,\n",
              " 'n_components': 2,\n",
              " 'node_num': 3,\n",
              " 'power_law_exp': inf,\n",
              " 'rel_edge_distr_entropy': 0.6308387341996874,\n",
              " 'square_count': 0,\n",
              " 'triangle_count': 0,\n",
              " 'wedge_count': 0.0}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bjmo9SNCmCrB",
        "colab_type": "code",
        "outputId": "16b454c8-f7f0-4ff7-c823-f88dcbb0612d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "import torch\n",
        "a = torch.Tensor([1]).cuda()\n",
        "print(a)\n",
        "torch.cuda.is_available()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([1.], device='cuda:0')\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lLRf3Q-_yBqi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import networkx as nx\n",
        "import copy\n",
        "\n",
        "# def show_graph(adj, bd, thresh=.5):\n",
        "#     if not isinstance(adj, np.ndarray):\n",
        "#         adj_ = adj.data.cpu().numpy()\n",
        "#     else:\n",
        "#         adj_ = copy.deepcopy(adj)\n",
        "#     # adj_ = adj_ / np.max(adj_)\n",
        "#     rows, cols = np.where(adj_ > thresh)\n",
        "#     if rows.size == 0:\n",
        "#         print('empty graph to print')\n",
        "#         return\n",
        "#     edges = zip(rows.tolist(), cols.tolist())\n",
        "#     gr = nx.Graph()\n",
        "#     gr.add_edges_from(edges)\n",
        "#     nx.draw(gr, node_size=30)\n",
        "#     plt.show()\n",
        "#     a = nx.to_numpy_array(gr)\n",
        "#     d = compute_graph_statistics(a)\n",
        "#     pprint(d)\n",
        "#     diff_d = {}\n",
        "    \n",
        "\n",
        "#     for k in list(d.keys()):\n",
        "#         diff_d[k] = abs(d[k] - bd[k])\n",
        "#     print((diff_d.keys()))\n",
        "#     print((diff_d.values()))\n",
        "#     return diff_d\n",
        "    \n",
        "\n",
        "def show_graph(adj, base_adj=None, remove_isolated=False):\n",
        "    if not isinstance(adj, np.ndarray):\n",
        "        adj_ = adj.data.cpu().numpy()\n",
        "    else:\n",
        "        adj_ = copy.deepcopy(adj)\n",
        "    \n",
        "    adj_ -= np.diag(np.diag(adj_))\n",
        "   \n",
        "    gr = nx.from_numpy_array(adj_)\n",
        "    assert((adj_ == adj_.T).all())\n",
        "    if remove_isolated:\n",
        "        gr.remove_nodes_from(list(nx.isolates(gr)))\n",
        "    nx.draw(gr, node_size=10)\n",
        "    plt.title('gen')\n",
        "    plt.show()\n",
        "    d = compute_graph_statistics(adj_)\n",
        "    pprint(d)\n",
        "    \n",
        "    if base_adj is not None:\n",
        "        base_gr = nx.from_numpy_array(base_adj)\n",
        "        nx.draw(base_gr, node_size=10)\n",
        "        plt.title('base')\n",
        "        plt.show()\n",
        "        bd = compute_graph_statistics(base_adj)\n",
        "        diff_d = {}\n",
        "        for k in list(d.keys()):\n",
        "            diff_d[k] = round(abs(d[k] - bd[k]), 4)\n",
        "        print(diff_d.keys())\n",
        "        print(diff_d.values())\n",
        "\n",
        "\n",
        "# def show_graph(adj, thresh=.5):\n",
        "#     if not isinstance(adj, np.ndarray):\n",
        "#         adj_ = adj.data.cpu().numpy()\n",
        "#     else:\n",
        "#         adj_ = copy.deepcopy(adj)\n",
        "#     # adj_ = adj_ / np.max(adj_)\n",
        "#     rows, cols = np.where(adj_ > thresh)\n",
        "#     if rows.size == 0:\n",
        "#         print('empty graph to print')\n",
        "#         return\n",
        "#     edges = zip(rows.tolist(), cols.tolist())\n",
        "#     gr = nx.Graph()\n",
        "#     gr.add_edges_from(edges)\n",
        "#     nx.draw(gr, node_size=30)\n",
        "#     plt.show()\n",
        "#     a = nx.to_numpy_array(gr)\n",
        "#     pprint(compute_graph_statistics(a))\n",
        "    \n",
        "        \n",
        "def make_symmetric(m):\n",
        "    m_ = torch.transpose(m)\n",
        "    w = torch.max(m_, m_.T)\n",
        "    return w\n",
        "\n",
        "\n",
        "def make_adj(x, n):\n",
        "    res = torch.zeros(n, n).cuda()\n",
        "    i = 0\n",
        "    for r in range(1, n):\n",
        "        for c in range(r, n):\n",
        "            res[r, c] = x[i]\n",
        "            res[c, r] = res[r, c]\n",
        "            i += 1\n",
        "    return res\n",
        "\n",
        "\n",
        "def cat_attr(x, attr_vec):\n",
        "    if attr_vec is None:\n",
        "        return x\n",
        "    attr_mat = attr_vec.repeat(x.size()[0], 1)\n",
        "    x = torch.cat([x, attr_mat], dim=1)\n",
        "    return x\n",
        "\n",
        "\n",
        "def get_spectral_embedding(adj, d):\n",
        "    \"\"\"\n",
        "    Given adj is N*N, return its feature mat N*D, D is fixed in model\n",
        "    :param adj:\n",
        "    :return:\n",
        "    \"\"\"\n",
        "    \n",
        "    adj_ = adj.data.cpu().numpy()\n",
        "    emb = SpectralEmbedding(n_components=d)\n",
        "    res = emb.fit_transform(adj_)\n",
        "    x = torch.from_numpy(res).float().cuda()\n",
        "    '''\n",
        "    x=torch.eye(adj.size()[0]).cuda()\n",
        "    '''\n",
        "    return x\n",
        "\n",
        "'''\n",
        "def normalize(mx):\n",
        "    \"\"\"Row-normalize sparse matrix\"\"\"\n",
        "    mx = mx.data.cpu().numpy()\n",
        "    mx += sp.eye(mx.shape[0])\n",
        "    rowsum = np.array(mx.sum(1))\n",
        "    r_inv = np.power(rowsum, -1).flatten()\n",
        "    r_inv[np.isinf(r_inv)] = 0.\n",
        "    r_mat_inv = sp.diags(r_inv)\n",
        "    mx = r_mat_inv.dot(mx)\n",
        "    return torch.from_numpy(mx).float().cuda()\n",
        "'''\n",
        "def normalize(adj):\n",
        "    adj = adj.data.cpu().numpy()\n",
        "    adj_ = adj + np.eye(adj.shape[0])\n",
        "    rowsum = np.array(adj_.sum(1))\n",
        "    degree_mat_inv_sqrt = np.diag(np.power(rowsum, -0.5).flatten())\n",
        "    degree_mat_sqrt = np.diag(np.power(rowsum, 0.5).flatten())\n",
        "    adj_normalized = degree_mat_inv_sqrt.dot(adj_).dot(degree_mat_sqrt)\n",
        "    return torch.from_numpy(adj_normalized).float().cuda()\n",
        "\n",
        "def preprocess_graph(adj):\n",
        "    adj = sp.coo_matrix(adj)\n",
        "    adj_ = adj + sp.eye(adj.shape[0])\n",
        "    rowsum = np.array(adj_.sum(1))\n",
        "    degree_mat_inv_sqrt = sp.diags(np.power(rowsum, -0.5).flatten())\n",
        "    adj_normalized = adj_.dot(degree_mat_inv_sqrt).transpose().dot(degree_mat_inv_sqrt).tocoo()\n",
        "    return sparse_to_tuple(adj_normalized)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VR7qg3rF_Z5d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from pprint import pprint\n",
        "# from collections import defaultdict\n",
        "\n",
        "# NODE_FILE = 'node.dat'\n",
        "# LINK_FILE = 'link.dat'\n",
        "# LABEL_FILE = 'label.dat'\n",
        "# DATA_DIR = 'data'\n",
        "# mat_names = []\n",
        "# adj_mats = []\n",
        "# id_maps = []\n",
        "\n",
        "# cnt = 0\n",
        "# for folder in os.listdir(DATA_DIR):\n",
        "#     cnt += 1\n",
        "#     if cnt > 100:\n",
        "#         break\n",
        "#     mat_names.append(folder)\n",
        "#     id_to_item = {}\n",
        "#     with open(os.path.join(DATA_DIR, folder, NODE_FILE), 'r') as f:\n",
        "#         for i, line in enumerate(f):\n",
        "#             cells = line.split('\\t')\n",
        "#             id_to_item[i] = cells[0]\n",
        "\n",
        "#     all_items = set(id_to_item.values())\n",
        "#     all_ids = set(id_to_item.keys())\n",
        "        \n",
        "#     links = defaultdict(set)\n",
        "#     with open(os.path.join(DATA_DIR, folder, LINK_FILE), 'r') as f:\n",
        "#         for line in f:\n",
        "#             cells = line.rstrip('\\n').split('\\t')\n",
        "#             from_id = int(cells[0])\n",
        "#             to_id = int(cells[1])\n",
        "#             if from_id in all_ids and to_id in all_ids:\n",
        "#                 links[from_id].add(to_id)\n",
        "    \n",
        "#     N = len(all_ids)\n",
        "#     adj = np.zeros((N, N))\n",
        "#     for from_id in range(N):\n",
        "#         for to_id in links[i]:\n",
        "#             adj[from_id, to_id] = 1\n",
        "#             adj[to_id, from_id] = 1\n",
        "#     id_map = [id_to_item[i] for i in range(N)]\n",
        "    \n",
        "#     adj_mats.append(adj)\n",
        "#     id_maps.append(id_map)\n",
        "    \n",
        "\n",
        "# t_adj_mats = [torch.from_numpy(m).float() for m in adj_mats]\n",
        "# torch.manual_seed(0)\n",
        "# t_attr_vecs = torch.randn(len(t_adj_mats), 8)\n",
        "    \n",
        "\n",
        "# for i in range(3):\n",
        "#     print('No:', i, mat_names[i])\n",
        "#     print('Adj Mat', adj_mats[i].shape)\n",
        "#     print(adj_mats[i])\n",
        "#     show_graph(adj_mats[i])\n",
        "#     print('# of nodes', len(id_maps[i]))\n",
        "#     print('# of links', np.count_nonzero(adj_mats[i]) // 2)\n",
        "#     print('Item names', id_maps[i])\n",
        "#     print('Attr vec', t_attr_vecs[i, :])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZfooBFdO5RL1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from pprint import pprint\n",
        "# from collections import defaultdict\n",
        "\n",
        "# NODE_FILE = 'sub.node.dat'\n",
        "# LINK_FILE = 'sub.link.dat'\n",
        "# LABEL_FILE = 'sub.label.dat'\n",
        "\n",
        "# id_to_author = {}\n",
        "# id_to_fv = {}\n",
        "# with open(NODE_FILE, 'r') as f:\n",
        "#     for i, line in enumerate(f):\n",
        "#         cells = line.split('\\t')\n",
        "#         if cells[1] == '1':\n",
        "#             id_to_author[i] = cells[0]\n",
        "#             id_to_fv[i] = np.asarray([float(a) for a in cells[-1].split(',')])\n",
        "# all_authors = set(id_to_author.values())\n",
        "# all_ids = set(id_to_author.keys())\n",
        "\n",
        "# sg_to_ids = defaultdict(list)\n",
        "# author_to_id = {v: k for k, v in id_to_author.items()}\n",
        "# with open(LABEL_FILE, 'r') as f:\n",
        "#     for line in f:\n",
        "#         cells = line.rstrip('\\n').split('\\t')\n",
        "#         if cells[1] == '1' and cells[0] in all_authors:\n",
        "#             sg_to_ids[int(cells[2])].append(author_to_id[cells[0]])\n",
        "# for k, v in sg_to_ids.items():\n",
        "#     v.sort()\n",
        "    \n",
        "# links = defaultdict(set)\n",
        "# with open(LINK_FILE, 'r') as f:\n",
        "#     for line in f:\n",
        "#         cells = line.rstrip('\\n').split('\\t')\n",
        "#         from_id = int(cells[0])\n",
        "#         to_id = int(cells[1])\n",
        "#         if from_id in all_ids and to_id in all_ids:\n",
        "#             links[from_id].add(to_id)\n",
        "# print('total links', sum(len(s) for s in links.values()))\n",
        "\n",
        "# adj_mats = []\n",
        "# id_maps = []\n",
        "# author_maps = []\n",
        "# feature_mats = []\n",
        "# M = len(id_to_fv[15055])\n",
        "# for sg, ids in sg_to_ids.items():\n",
        "#     N = len(ids)\n",
        "#     cur_ids = set(ids)\n",
        "#     adj_mat = np.zeros((N, N))\n",
        "#     feature_mat = np.zeros((N, M))\n",
        "#     row_map = {id: i for i, id in enumerate(ids)}\n",
        "#     for id in ids:\n",
        "#         for to_id in links[id]:\n",
        "#             if to_id not in cur_ids:\n",
        "#                 continue\n",
        "#             r = row_map[id]\n",
        "#             c = row_map[to_id]\n",
        "#             adj_mat[r, c] = 1\n",
        "#             adj_mat[c, r] = 1\n",
        "#             feature_mat[r, :] = id_to_fv[id]\n",
        "#     adj_mats.append(adj_mat)\n",
        "#     id_maps.append(ids)\n",
        "#     author_maps.append([id_to_author[id] for id in ids])\n",
        "#     feature_mats.append(feature_mat)\n",
        "\n",
        "# for i in range(len(adj_mats)):\n",
        "#     print('Sub Group:', i)\n",
        "#     print('Adj Mat', adj_mats[i].shape)\n",
        "#     print(adj_mats[i])\n",
        "#     print('Feature Mat', feature_mats[i].shape)\n",
        "#     print(feature_mats[i])\n",
        "#     print('# of nodes', len(id_maps[i]))\n",
        "#     print('# of links', np.count_nonzero(adj_mats[i]) // 2)\n",
        "#     print('Author IDs', id_maps[i])\n",
        "#     print('Author Names', author_maps[i])\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "77cXgy9wy7FU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def keep_topk_conns(adj, k=3):\n",
        "    g = nx.from_numpy_array(adj)\n",
        "    to_removes = [cp for cp in sorted(nx.connected_components(g), key=len)][:-k]\n",
        "    for cp in to_removes:\n",
        "        g.remove_nodes_from(cp)\n",
        "    adj = nx.to_numpy_array(g)\n",
        "    return adj\n",
        "\n",
        "\n",
        "def remove_small_conns(adj, keep_min_conn=4):\n",
        "    g = nx.from_numpy_array(adj)\n",
        "    for cp in list(nx.algorithms.components.connected_components(g)):\n",
        "        if len(cp) < keep_min_conn:\n",
        "            g.remove_nodes_from(cp)\n",
        "    adj = nx.to_numpy_array(g)\n",
        "    return adj"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2SnP-jQeyh7U",
        "colab_type": "code",
        "outputId": "a409f22b-ba96-4f62-8877-9b80dc860dbf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1448
        }
      },
      "source": [
        "# script for loading NWE dblp\n",
        "# folder structure\n",
        "# - this.ipynb\n",
        "# - $DATA_DIR - *.txt\n",
        "\n",
        "from pprint import pprint\n",
        "from collections import defaultdict\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "NODE_FILE = 'node.dat'\n",
        "LINK_FILE = 'link.dat'\n",
        "LABEL_FILE = 'label.dat'\n",
        "ATTR_FILE = 'attribute.dat'\n",
        "DATA_DIR = 'PGG_dblp'\n",
        "mat_names = []  # e.g. GSE_2304\n",
        "adj_mats = []  # essential data, type: list(np.ndarray)\n",
        "attr_vecs = [] # essential data, type: list(np.ndarray)\n",
        "id_maps = []  # map index to gene name if you need\n",
        "\n",
        "for f in os.listdir(DATA_DIR):\n",
        "    if not f.startswith(('nodes', 'links', 'attrs')):\n",
        "        continue\n",
        "    else:\n",
        "        mat_names.append('_'.join(f.split('.')[0].split('_')[1:]))\n",
        "mat_names = sorted([it for it in set(mat_names)])\n",
        "print(mat_names)\n",
        "print('Test length', len(mat_names))\n",
        "for mat_name in mat_names:\n",
        "    node_file = 'nodes_' + mat_name + '.txt'\n",
        "    link_file = 'links_' + mat_name + '.txt'\n",
        "    attr_file  = 'attrs_' + mat_name + '.txt'\n",
        "    node_file_path = os.path.join(DATA_DIR, node_file)\n",
        "    link_file_path = os.path.join(DATA_DIR, link_file)\n",
        "    attr_file_path = os.path.join(DATA_DIR, attr_file)\n",
        "    \n",
        "    id_to_item = {}\n",
        "    with open(node_file_path, 'r') as f:\n",
        "        for i, line in enumerate(f):\n",
        "            author = line.rstrip('\\n')\n",
        "            id_to_item[i] = author\n",
        "    all_ids = set(id_to_item.keys())\n",
        "    \n",
        "    with open(attr_file_path, 'r') as f:\n",
        "        attr_vec = np.loadtxt(f).T.flatten()\n",
        "        attr_vecs.append(attr_vec)\n",
        "    \n",
        "    links = defaultdict(set)\n",
        "    with open(link_file_path, 'r') as f:\n",
        "        for line in f:\n",
        "            cells = line.rstrip('\\n').split(',')\n",
        "            from_id = int(cells[0])\n",
        "            to_id = int(cells[1])\n",
        "            if from_id in all_ids and to_id in all_ids:\n",
        "                links[from_id].add(to_id)\n",
        "    \n",
        "    N = len(all_ids)\n",
        "    adj = np.zeros((N, N))\n",
        "    for from_id in range(N):\n",
        "        for to_id in links[from_id]:\n",
        "            adj[from_id, to_id] = 1\n",
        "            adj[to_id, from_id] = 1\n",
        "            \n",
        "    adj -= np.diag(np.diag(adj))\n",
        "    id_map = [id_to_item[i] for i in range(N)]\n",
        "    \n",
        "    \n",
        "    # Remove small component\n",
        "    # adj = remove_small_conns(adj, keep_min_conn=4)\n",
        "    \n",
        "    # Keep large component \n",
        "    adj = keep_topk_conns(adj, k=1)\n",
        "    adj_mats.append(adj)\n",
        "    id_maps.append(id_map)\n",
        "    \n",
        "    if int(np.sum(adj)) == 0:\n",
        "        adj_mats.pop(-1)\n",
        "        id_maps.pop(-1)\n",
        "        mat_names.pop(-1)\n",
        "        attr_vecs.pop(-1)\n",
        "                \n",
        "        \n",
        "        \n",
        "# print some samples\n",
        "for i in range(5):\n",
        "    print('No:', i, mat_names[i])\n",
        "    print('Adj Mat', adj_mats[i].shape)\n",
        "    print(adj_mats[i])\n",
        "    print('# of nodes', len(id_maps[i]))\n",
        "    print('# of links', np.count_nonzero(adj_mats[i]) // 2)\n",
        "    print('Atrribute vector', attr_vecs[i].shape)\n",
        "    print(attr_vecs[i])\n",
        "    print('Item names', id_maps[i])\n",
        "    print('Components')\n",
        "    print(list(nx.algorithms.components.connected_components(nx.from_numpy_array(adj_mats[i]))))\n",
        "    \n",
        "train_adj_mats = adj_mats[:int(len(adj_mats) * .8)]\n",
        "test_adj_mats = adj_mats[int(len(adj_mats) * .8):]\n",
        "train_attr_vecs = attr_vecs[:int(len(attr_vecs) * .8)]\n",
        "test_attr_vecs = attr_vecs[int(len(attr_vecs) * .8):]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['ckim_00-09_0-10', 'ckim_00-09_10-30', 'ckim_00-09_30+', 'ckim_10-19_0-10', 'ckim_10-19_10-30', 'ckim_10-19_30+', 'ckim_90-99_0-10', 'ckim_90-99_10-30', 'ckim_90-99_30+', 'icdm_00-09_0-10', 'icdm_00-09_10-30', 'icdm_00-09_30+', 'icdm_10-19_0-10', 'icdm_10-19_10-30', 'icdm_10-19_30+', 'icdm_90-99_0-10', 'icdm_90-99_10-30', 'icdm_90-99_30+', 'icml_00-09_0-10', 'icml_00-09_10-30', 'icml_00-09_30+', 'icml_10-19_0-10', 'icml_10-19_10-30', 'icml_10-19_30+', 'icml_90-99_0-10', 'icml_90-99_10-30', 'icml_90-99_30+', 'kdd_00-09_0-10', 'kdd_00-09_10-30', 'kdd_00-09_30+', 'kdd_10-19_0-10', 'kdd_10-19_10-30', 'kdd_10-19_30+', 'kdd_90-99_0-10', 'kdd_90-99_10-30', 'kdd_90-99_30+', 'nips_00-09_0-10', 'nips_00-09_10-30', 'nips_00-09_30+', 'nips_10-19_0-10', 'nips_10-19_10-30', 'nips_10-19_30+', 'nips_90-99_0-10', 'nips_90-99_10-30', 'nips_90-99_30+', 'sigir_00-09_0-10', 'sigir_00-09_10-30', 'sigir_00-09_30+', 'sigir_10-19_0-10', 'sigir_10-19_10-30', 'sigir_10-19_30+', 'sigir_90-99_0-10', 'sigir_90-99_10-30', 'sigir_90-99_30+', 'sigmod_00-09_0-10', 'sigmod_00-09_10-30', 'sigmod_00-09_30+', 'sigmod_10-19_0-10', 'sigmod_10-19_10-30', 'sigmod_10-19_30+', 'sigmod_90-99_0-10', 'sigmod_90-99_10-30', 'sigmod_90-99_30+', 'vldb_00-09_0-10', 'vldb_00-09_10-30', 'vldb_00-09_30+', 'vldb_10-19_0-10', 'vldb_10-19_10-30', 'vldb_10-19_30+', 'vldb_90-99_0-10', 'vldb_90-99_10-30', 'vldb_90-99_30+']\n",
            "Test length 72\n",
            "No: 0 ckim_00-09_0-10\n",
            "Adj Mat (3, 3)\n",
            "[[0. 1. 1.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]]\n",
            "# of nodes 20\n",
            "# of links 2\n",
            "Atrribute vector (10,)\n",
            "[0. 0. 0. 0. 0. 1. 0. 0. 2. 1.]\n",
            "Item names ['Ruijie Guo', 'Devanand Ravindran', 'Vaughan R. Shanks', 'Julia Luxenburger', 'Ao Feng', 'Wahyu Wibowo', 'Jason Chaffee', 'Alireza Mokhtaripour', 'Karane Vieira', 'Giorgos Margaritis', 'Nasreen AbdulJaleel', 'Bin Lan', 'Cheng-Yue Chang', 'Jeff Pasternack', 'Mingjie Zhu', 'Ahu Sieg', 'Sairam Gurajada', 'Kashif Riaz', 'Stephen Cronen-Townsend', 'Christian Kohlschütter']\n",
            "Components\n",
            "[{0, 1, 2}]\n",
            "No: 1 ckim_00-09_10-30\n",
            "Adj Mat (7, 7)\n",
            "[[0. 1. 1. 1. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 1. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1. 1.]\n",
            " [0. 0. 1. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0. 0.]]\n",
            "# of nodes 80\n",
            "# of links 6\n",
            "Atrribute vector (10,)\n",
            "[0. 0. 0. 0. 0. 1. 0. 0. 2. 2.]\n",
            "Item names ['Falk Brauer', 'James J. Gardner', 'Paul-Alexandru Chirita', 'Moshe Fresko', 'Jangwon Seo', 'Wenhui Liao', 'Chong Long', 'Bhuvan Bamba', 'Leah S. Larkey', 'Hao-Ping Hung', 'Li Zhuang', 'Dongmei Jia', 'Stefan Büttcher', 'Derrick Coetzee', 'Ding Zhou', 'Eduarda Mendes Rodrigues', 'Oisín Boydell', 'Pawel Jurczyk', 'Paavo Arvola', 'Rebecca Cathey', 'Benjamin Rosenfeld', 'Hongliang Fei', 'Linhong Zhu', 'Maryam Karimzadehgan', 'Lixin Shi', 'Chun Tang', 'Kerstin Bischoff', 'Lilian Harada', 'Nicholas Lester', 'Le Zhao', 'James W. Cooper', 'Bodo Billerbeck', 'Bingjun Sun', 'Qiankun Zhao', 'Eric C. Jensen', 'Shui-Lung Chuang', 'Munirathnam Srikanth', 'Xuehua Shen', 'Beverly Yang', 'Xiaoguang Qi', 'Andrew Hickl', 'Eric J. Glover', 'Marina Barsky', 'Timothy G. Armstrong', 'Zheng-Yu Niu', 'Chih-Chin Liu', 'Lingpeng Yang', 'Asad B. Sayeed', 'Abhishek Mukherji', 'Susan Price', 'Sarah Zelikovitz', 'Changzhou Wang', 'Hyun Duk Kim', 'Chang-Hung Lee', 'Jack G. Conrad', 'Thomas R. Lynam', 'David N. Milne', 'Changqing Li', 'Viet Ha-Thuc', 'David Liben-Nowell', 'Zhicheng Dou', 'Caimei Lu', 'Desmond Elliott', 'Joong Hyuk Chang', 'Ramakrishna Varadarajan', 'Dongmei Ren', 'Prasan Roy', 'Xiaoyong Liu', 'Ramesh Nallapati', 'Vuk Ercegovac', 'Paul Ogilvie', 'Fabien Duchateau', 'Flavio Figueiredo', 'Like Gao', 'Xianpei Han', 'Kamal Nigam', 'Jiwoon Jeon', 'Stefanos Souldatos', 'Einat Amitay', 'Cai-Nicolas Ziegler']\n",
            "Components\n",
            "[{0, 1, 2, 3, 4, 5, 6}]\n",
            "No: 2 ckim_00-09_30+\n",
            "Adj Mat (76, 76)\n",
            "[[0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " ...\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]]\n",
            "# of nodes 194\n",
            "# of links 84\n",
            "Atrribute vector (10,)\n",
            "[0. 0. 0. 0. 0. 1. 0. 0. 2. 3.]\n",
            "Item names ['Fabian Abel', 'Shuming Shi', 'Edgar Meij', 'Ronny Lempel', 'Yi Ma', 'Valentin Jijkoun', 'Emine Yilmaz', 'Vana Kalogeraki', 'Ben He', 'Sebastian Michel', 'Doron Rotem', 'Nick Koudas', 'Benjamin Piwowarski', 'Sujith Ravi', 'Leif Azzopardi', 'Xiang Lian', 'Luis Gravano', 'Azadeh Shakery', 'Claudia Hauff', 'Georgios Paltoglou', 'Hao Ma', 'Pável Calado', 'Jiaheng Lu', 'Petteri Nurmi', 'Marius Pasca', 'Gilad Mishne', 'Lei Wu', 'Xiaoyan Li', 'Hwanjo Yu', 'Ali Dasdan', 'Chen Chen', 'Ming Zhong', 'William Webber', 'Bin Wu', 'Yangqiu Song', 'Kevyn Collins-Thompson', 'David Grangier', 'Jure Leskovec', 'Dimitri Theodoratos', 'Anand Ranganathan', 'Amit Anil Nanavati', 'Ning Liu', 'Tomonari Masada', 'Qiaozhu Mei', 'Karl Aberer', 'David E. Losada', 'Shixia Liu', 'Bo Long', 'Gui-Rong Xue', 'Daniel Barbará', 'Rayid Ghani', 'Jin Zhang', 'Ömer Eğecioğlu', 'Yi-Leh Wu', 'Olivier Chapelle', 'Massimo Melucci', 'Linyuan Lü', 'Wei Zhang', 'Wei Dong', 'Ranieri Baraglia', 'Jianliang Xu', 'Wookey Lee', 'Bin Liu', 'Falk Scholer', 'Rosie Jones', 'Tetsuya Sakai', 'Paolo Boldi', 'Ana Gabriela Maguitman', 'Li Ding', 'Alberto Lavelli', 'Luo Si', 'Xin Xin', 'Adriano Veloso', 'Bing Bai', 'Chia-Jung Lee', 'James Allan', 'Jing He', 'Nan Ma', 'Hua Yan', 'Jianguo Lu', 'Youngja Park', 'Donald Metzler', 'Changhu Wang', 'Ying Zhao', 'Xiaojun Wan', 'Hang Li', 'Yun Zhou', 'Kamesh Madduri', 'Dmitri Roussinov', 'Peter Bailey', 'Andrei Z. Broder', 'Robert West', 'Krisztian Balog', 'Jeremy Pickens', 'Umit Y. Ogras', 'Gang Luo', 'Jie Lu', 'Chirag Shah', 'Victor Lavrenko', 'Ryen W. White', 'Fernando Diaz', 'Songbo Tan', 'Kai-Uwe Sattler', 'Reynold Cheng', 'Leonardo C. da Rocha', 'Ning Jin', 'Craig Macdonald', 'Yang Song', 'Keke Chen', 'Hongyuan Zha', 'Sara Cohen', 'Xin Liu', 'Yue Xu', 'Dragomir R. Radev', 'Bo Wang', 'Jaap Kamps', 'Xuanhui Wang', 'Krysta M. Svore', 'Pavel Serdyukov', 'Sourav S. Bhowmick', 'Charles L. A. Clarke', 'Jeff Huang', 'Doug Downey', 'Sam Yuan Sung', 'David Fernandes', 'Furu Wei', 'Kun Lung Wu', 'Stephen E. Robertson', 'Takao Miura', 'Dingding Wang', 'Xiaoli Li', 'Victor Muntés-Mulero', 'Jun Wang', 'Javed A. Aslam', 'Carlos Ordonez', 'Christos Doulkeridis', 'Marc Najork', 'Peter D. Bruza', 'Xin Cao', 'Sheng Guo', 'Hugo Zaragoza', 'Lipyeow Lim', 'Li Ma', 'Deepak Agarwal', 'Huanhuan Cao', 'Shuang Liu', 'Shenghua Bao', 'Qiang Huang', 'Yuanhua Lv', 'Yuefeng Li', 'Qin Lv', 'Jing Bai', 'Rada Mihalcea', 'Wei Dai', 'Jimmy J. Lin', 'Katja Hose', 'James P. Callan', 'Matthew Lease', 'Fabrizio Sebastiani', 'Ben Carterette', 'Tapas Kanungo', 'Ping Luo', 'Wai Gen Yee', 'Gianluca Demartini', 'Yuqing Wu', 'Francisco M. Couto', 'Mark D. Smucker', 'Hakan Ferhatosmanoglu', 'Guoliang Li', 'Ke Sun', 'Zaiqing Nie', 'Xin Li', 'William E. Jones', 'Yi Ding', 'Ling Ma', 'Kang Liu', 'Jinyoung Kim', 'Anton Leuski', 'Bin He', 'Jaime Arguello', 'Andrea Esuli', 'Aris Anagnostopoulos', 'Bin Cao', 'Ziv Bar-Yossef', 'Hui Li', 'David Carmel', 'Anoop Singhal', 'Takahiro Hara', 'Jiun-Long Huang', 'ChengXiang Zhai', 'Filip Radlinski', 'Aleksander Kolcz', 'Dou Shen', 'Jie Peng']\n",
            "Components\n",
            "[{0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75}]\n",
            "No: 3 ckim_10-19_0-10\n",
            "Adj Mat (12, 12)\n",
            "[[0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
            " [1. 1. 0. 0. 0. 1. 1. 1. 0. 1. 1. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]]\n",
            "# of nodes 156\n",
            "# of links 12\n",
            "Atrribute vector (10,)\n",
            "[0. 0. 0. 0. 0. 1. 0. 0. 3. 1.]\n",
            "Item names ['Cane Wing-Ki Leung', 'Sami Abu-El-Haija', 'Minh C. Phan', 'Hagit Cohen', 'Yu-Hsuan Kuo', 'Xin-Chao Xu', 'Tomasz Kusmierczyk', 'Niels Dalum Hansen', 'Meike Zehlike', 'Sairam Gurajada', 'Raíza Hanada', 'John S. Whissell', 'Avikalp Srivastava', 'Ali Braytee', 'Anton Bakhtin', 'Silvia Rota', 'Lijing Qin', 'Rudra M. Tripathy', 'Anahita Hosseini', 'Abhishek Sikchi', 'Imrul Chowdhury Anindya', 'Giuseppe Amodeo', 'Ryadh Dahimene', 'Snehasis Banerjee', 'Tuan-Anh Hoang-Vu', 'Chonggang Song', 'Henry Vieira', 'Satoshi Sanjo', 'Wenjie Pei', 'Rana Hussein', 'Alican Büyükçakir', 'Alejandro Marcos Alvarez', 'Jun-Gi Jang', 'Kerui Min', 'Matthew W. Bilotti', 'Sandro Cavallari', 'Feruz Davletov', 'Ha-Myung Park', 'Wen Chan', 'Shaosheng Cao', 'Andrey Styskin', 'Adit Krishnan', 'Chia-An Yu', 'Lance De Vine', 'Ramakrishna Bairi', 'Zongcheng Ji', 'Mengdie Zhuang', 'Maxim Zhukovskiy', 'William Lucia', 'Wang-Cheng Kang', 'Xian Teng', 'Melissa Ailem', 'Walther Neuper', 'Zhen Liao', 'Casper Worm Hansen', 'Jiongqian Liang', 'Ruben Sipos', 'Tao Yang Fu', 'Yujie Fan', 'Weiyi Xia', 'Jatin Arora', 'Konstantin Tretyakov', 'Nico Schlaefer', 'Gad Markovits', 'Swapnil Mishra', 'Amin Y. Teymorian', 'Yusra Ibrahim', 'Jiangfeng Zeng', 'Alfan Farizki Wicaksono', 'Biao Chang', 'Jasper Linmans', 'Sergio Duarte Torres', 'Qizhen Zhang', 'Kezun Zhang', 'Shiwen Cheng', 'Zhen Hai', 'Elif Aktolga', 'Xuntao Cheng', 'Myungha Jang', 'Yaogong Zhang', 'Yonathan Perez', 'Mustafa Zengin', 'Zhiyuan Cai', 'Nikita V. Spirin', 'Weihuang Huang', 'Jeffrey McGee', 'Daniele Broccolo', 'Hamed R. Bonab', 'Bilyana Taneva', 'Joel Coffman', 'Yuli Liu', 'Saiping Guan', 'Shiri Dori-Hacohen', 'Thomas Stone', 'Omar Khattab', 'Bing-Jie Sun', 'Kai-Yang Chiang', 'Maria Christoforaki', 'Shitao Zhang', 'Wanying Ding', 'Hideaki Kim', 'Boris Sharchilev', 'Matteo Catena', 'Weize Kong', 'Sumita Barahmand', 'S. Cheng', 'Zhuoyu Wei', 'Caitlin Kuhlman', 'Andrey Kustarev', 'Erdal Kuzey', 'Sarah K. Tyler', 'Kais Allab', 'Joon Hee Kim', 'Shubhra Kanti Karmaker Santu', 'Zhaochen Guo', 'Qiongkai Xu', 'Chen Chu', 'Thông T. Nguyên', 'Ridho Reinanda', 'Radityo Eko Prasojo', 'Huiyuan Chen', 'Yuling Shi', 'Thông T. Nguyễn', 'Haochen Chen', 'Sarah Masud Preum', 'Alexey Baytin', 'Seyyedeh Newsha Ghoreishi', 'Nelly Vouzoukidou', 'Kajta Hofmann', 'Afroza Sultana', 'Renqin Cai', 'Fanghua Ye', 'Maksim Tkachenko', 'Feza Baskaya', 'Tung Kieu', 'Dejian Yang', 'Tianshu Lyu', 'Chaozhuo Li', 'Yann Jacob', 'Xiaojia Pu', 'Ruicheng Zhong', 'Qiyun Zhao', 'Edoardo Galimberti', 'Tarique Siddiqui', 'Dwaipayan Roy', 'Zhung-Xun Liao', 'Namyong Park', 'Behrooz Mansouri', 'Rawia Awadallah', 'Mark Wilhelm', 'Chen Tse Tsai', 'Muhammad Ali Norozi', 'Qitian Wu', 'Ahmet Murat Ozdemiray', 'Jianglei Han', 'Razvan-Gabriel Cirstea']\n",
            "Components\n",
            "[{0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11}]\n",
            "No: 4 ckim_10-19_10-30\n",
            "Adj Mat (74, 74)\n",
            "[[0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " ...\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]]\n",
            "# of nodes 262\n",
            "# of links 86\n",
            "Atrribute vector (10,)\n",
            "[0. 0. 0. 0. 0. 1. 0. 0. 3. 2.]\n",
            "Item names ['Mohamed E. Khalefa', 'Benjamin Roth', 'Mehdi Hosseini', 'Yunlong He', 'Michael L. Wick', 'Minkyoung Kim', 'Mehdi Kargar', 'Michael Schuhmacher', 'Jiafeng Hu', 'Runwei Qiang', 'Julia Kiseleva', 'Qiyue Yin', 'Yong-Yeon Jo', 'Suppawong Tuarob', 'Ian Wood', 'Jonathan Gemmell', 'Einat Minkov', 'Jiaming Shen', 'Kyosuke Nishida', 'Guoliang He', 'Mansurul Bhuiyan', 'Taiki Miyanishi', 'Luca Bonomi', 'Yelong Shen', 'Abhijith Kashyap', 'Po-Sen Huang', 'Victor W. Chu', 'Wenyi Huang', 'Andrey Gubichev', 'Romain Deveaud', 'Zhiyuan Cheng', 'Carolina Bonacic', 'Jeffrey Pound', 'Yunzhong Liu', 'Yafang Wang', 'Daifeng Li', 'Yuto Yamaguchi', 'Jiangtao Yin', 'Pritam Gundecha', 'Ruey-Cheng Chen', 'George D. Montanez', 'Damien Lefortier', 'Yin Zhu', 'Kateryna Tymoshenko', 'Chenxi Qiu', 'Aditya Pal', 'Jinfeng Rao', 'Alan Medlar', 'Seyyed Hadi Hashemi', 'Henning Koehler', 'Tianbing Xu', 'Suhas Ranganath', 'Jia-Dong Zhang', 'Jyun-Yu Jiang', 'Ioannis Arapakis', 'Zhen Yue', 'Dinusha Vatsalan', 'Elad Kravi', 'Maksims Volkovs', 'Samaneh Moghaddam', 'Takanori Hayashi', 'Fajie Yuan', 'Joyce Jiyoung Whang', 'Dae Hoon Park', 'Aleksandr Chuklin', 'Zheng Lin', 'Krishna Yeswanth Kamath', 'Huizhong Duan', 'Michael Völske', 'Yosi Mass', 'Ahmed Hassan Awadallah', 'Ariyam Das', 'Laure Soulier', 'Agus Trisnajaya Kwee', 'Ricardo Campos', 'Marek Ciglan', 'Xiaobing Xue', 'Duck-Ho Bae', 'Eugene Kharitonov', 'Gabriele Tolomei', 'Weiguo Zheng', 'Mingjie Qian', 'Feifan Fan', 'Abdigani Diriye', 'Laura Dietz', 'Markus Rokicki', 'Xiaoxue Zhao', 'Anne Schuth', 'Haishuai Wang', 'Mohammad Aliannejadi', 'Seongsoon Kim', 'Zhuoren Jiang', 'Maryam Karimzadehgan', 'Merih Seran Uysal', 'Mostafa Keikha', 'M-Dyaa Albakour', 'Qifan Wang', 'Lars Borin', 'Massimo Nicosia', 'Jiajia Huang', 'Fiana Raiber', 'Guoqiong Liao', 'Ziawasch Abedjan', 'Quanzhi Li', 'Sérgio D. Canuto', 'Shizhu He', 'Liang Pang', 'Simon Knight', 'Hossein Soleimani', 'Kan Ren', 'Jarana Manotumruksa', 'Sha Li', 'Abhishek Mukherji', 'George Valkanas', 'Hyun Duk Kim', 'Jan Vosecky', 'Kumaripaba Athukorala', 'Pengcheng Yin', 'Jae Hyun Park', 'Dhruv Mahajan', 'Christophe Van Gysel', 'Jialong Han', 'Cheng Cao', 'Shu Huang', 'Gaurav Baruah', 'Diego Ceccarelli', 'Yu Rong', 'Noriaki Kawamae', 'Ilaria Bordino', 'Gianni Amati', 'Henning Köhler', 'Bhaskar Mitra', 'Nitin Jindal', 'Marc Bron', 'Stewart Whiting', 'Nicole Bidoit', 'Kaiqi Zhao', 'Tuan A. Tran', 'Mijung Kim', 'Chenyan Xiong', 'Mahashweta Das', 'Jaeho Choi', 'Yuhao Yang', 'NhatHai Phan', 'Shangsong Liang', 'Rishabh Mehrotra', 'Arturas Mazeika', 'Erheng Zhong', 'Anjie Fang', 'Xinsheng Li', 'Chen Ma', 'Chih-Ya Shen', 'Dong-Kyu Chae', 'Tom Kenter', 'Marina Drosou', 'Anagha Kulkarni', 'Christoph Böhm', 'Mohamed Yahya', 'Yiwei Wang', 'Chong Peng', 'Hosein Azarbonyad', 'Maram Hasanain', 'Mo Zhou', 'Xiaohui Yan', 'Le Zhao', 'Melanie Herschel', 'Joseph J. Pfeiffer', 'Martin Szummer', 'Takuya Akiba', 'Xueke Xu', 'Veli Bicer', 'Felipe Viegas', 'Tianyi Lin', 'Olivier Van Laere', 'Leonid Boytsov', 'Ilya Markov', 'Nadav Golbandi', 'Tarique Anwar', 'Bin Tong', 'Roberto Mirizzi', 'Janette Lehmann', 'Xinhui Tu', 'Jiwoon Ha', 'Yuhao Zhang', 'Chee Wee Leong', 'Atsushi Miyauchi', 'Zi Yang', 'Won-Seok Hwang', 'Peifeng Yin', 'Huizhi Liang', 'Shenghua Liu', 'Chengyao Chen', 'Noa Avigdor-Elgrabli', 'Rianne Kaptein', 'Yiyang Li', 'Ximing Li', 'Xiaofei Zhu', 'Behzad Golshan', 'Guohua Liang', 'Honglei Guo', 'Silviu Maniu', 'Bei Shi', 'Miao Fan', 'Mossaab Bagdouri', 'Jinfei Liu', 'Kunwoo Park', 'Harrie Oosterhuis', 'Shady Elbassuoni', 'Zhao Kang', 'Colin Wilkie', 'Hongliang Fei', 'Jianming Lv', 'Nut Limsopatham', 'Xitong Liu', 'Baichuan Zhang', 'Luis Galárraga', 'Xufei Wang', 'Donghyuk Shin', 'Xiaomo Liu', 'Meng Fang', 'Johannes Hoffart', 'Jiaul H. Paik', 'Alessandro Sordoni', 'Avirup Sil', 'Alexey Drutsa', 'Xiaoxiao Shi', 'Henning Wachsmuth', 'Changsha Ma', 'Miika Hannula', 'Fangzhao Wu', 'Marina Danilevsky', 'Stephan Seufert', 'Luchen Tan', 'Luke K. McDowell', 'Panagiotis Liakos', 'Ou Jin', 'John Foley', 'Jiguang Liang', 'Baichuan Li', 'Xilun Chen', 'Chenliang Li', 'Yeyun Gong', 'Hancheng Ge', 'Peng Bao', 'Javid Ebrahimi', 'Vinay Deolalikar', 'Anqi Cui', 'Zhicheng Dou', 'Yang Bao', 'Ethem F. Can', 'Royi Ronen', 'Guy Feigenblat', 'Lars Kolb', 'Yuanyuan Zhu', 'Boxiang Dong', 'Muhammad Anis Uddin Nasir', 'D.J. Maxwell', 'Marc-Allen Cartright', 'Zongyang Ma', 'Joshua V. Dillon', 'Abir De', 'Behrooz Omidvar-Tehrani']\n",
            "Components\n",
            "[{0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73}]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BFYZdyIBxvm0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "def show_graph(adj, base_adj=None, remove_isolated=True):\n",
        "    if not isinstance(adj, np.ndarray):\n",
        "        adj_ = adj.data.cpu().numpy()\n",
        "    else:\n",
        "        adj_ = copy.deepcopy(adj)\n",
        "    \n",
        "    adj_ -= np.diag(np.diag(adj_))\n",
        "   \n",
        "    gr = nx.from_numpy_array(adj_)\n",
        "    assert((adj_ == adj_.T).all())\n",
        "    if remove_isolated:\n",
        "        gr.remove_nodes_from(list(nx.isolates(gr)))\n",
        "    nx.draw(gr, node_size=10)\n",
        "    plt.title('gen')\n",
        "    plt.show()\n",
        "    \n",
        "    d = compute_graph_statistics(adj_)\n",
        "    pprint(d)\n",
        "    \n",
        "    if base_adj is not None:\n",
        "        base_gr = nx.from_numpy_array(base_adj)\n",
        "        nx.draw(base_gr, node_size=10)\n",
        "        plt.title('base')\n",
        "        plt.show()\n",
        "        bd = compute_graph_statistics(base_adj)\n",
        "        diff_d = {}\n",
        "        for k in list(d.keys()):\n",
        "            diff_d[k] = round(abs(d[k] - bd[k]), 4)\n",
        "        print(diff_d.keys())\n",
        "        print(diff_d.values())\n",
        "\n",
        " "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2G6jPSY1zYht",
        "colab_type": "code",
        "outputId": "aac8d7a4-4f05-4cac-e77a-4dd8e4568c09",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1787
        }
      },
      "source": [
        "print(len(train_adj_mats))\n",
        "print(len(test_adj_mats))\n",
        "print(len(adj_mats))\n",
        "\n",
        "for i in range(3):\n",
        "    a = train_adj_mats[i]\n",
        "    show_graph(a) # There should be a bds[i]\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "52\n",
            "14\n",
            "66\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAb4AAAE+CAYAAADyPXUxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nS+HwAQAshcMHALCU/wN7JrlCqBOqDAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "{'LCC': 3,\n",
            " 'claw_count': 0.0,\n",
            " 'cpl': 1.3333333333333333,\n",
            " 'd': 1.3333333333333333,\n",
            " 'd_max': 2.0,\n",
            " 'd_min': 1.0,\n",
            " 'edge_num': 2,\n",
            " 'gini': -0.4999999999999999,\n",
            " 'n_components': 1,\n",
            " 'node_num': 3,\n",
            " 'power_law_exp': 5.328085122666891,\n",
            " 'rel_edge_distr_entropy': 0.946326365259516,\n",
            " 'square_count': 0,\n",
            " 'triangle_count': 0,\n",
            " 'wedge_count': 1.0}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAb4AAAE+CAYAAADyPXUxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAC2QvEBAGzl/wBUo6tqz7cszwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "{'LCC': 7,\n",
            " 'claw_count': 1.0,\n",
            " 'cpl': 2.4761904761904763,\n",
            " 'd': 1.7142857142857142,\n",
            " 'd_max': 3.0,\n",
            " 'd_min': 1.0,\n",
            " 'edge_num': 6,\n",
            " 'gini': -0.0714285714285714,\n",
            " 'n_components': 1,\n",
            " 'node_num': 7,\n",
            " 'power_law_exp': 3.2026058631088743,\n",
            " 'rel_edge_distr_entropy': 0.9577120798337921,\n",
            " 'square_count': 0,\n",
            " 'triangle_count': 0,\n",
            " 'wedge_count': 6.0}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAb4AAAE+CAYAAADyPXUxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nCCGEyJT/AwCn11z1rBfXAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "{'LCC': 76,\n",
            " 'claw_count': 249.0,\n",
            " 'cpl': 6.415087719298246,\n",
            " 'd': 2.210526315789474,\n",
            " 'd_max': 10.0,\n",
            " 'd_min': 1.0,\n",
            " 'edge_num': 84,\n",
            " 'gini': 0.33286340852130336,\n",
            " 'n_components': 1,\n",
            " 'node_num': 76,\n",
            " 'power_law_exp': 2.7351216464482864,\n",
            " 'rel_edge_distr_entropy': 0.9474673548740912,\n",
            " 'square_count': 0,\n",
            " 'triangle_count': 5,\n",
            " 'wedge_count': 206.0}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kofZ2jjlG2G1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# t_adj_mats = [torch.from_numpy(m).float() for m in adj_mats]\n",
        "# t_attr_vecs = torch.eye(len(adj_mats))\n",
        "# bds = [compute_graph_statistics(adj_mats[i]) for i in range(len(t_adj_mats))]\n",
        "\n",
        "# for i in range(len(t_adj_mats)):\n",
        "#     print(t_attr_vecs[i])\n",
        "#     a = t_adj_mats[i]\n",
        "#     print('i:', i, 'bds',bds[i])\n",
        "    \n",
        "#     #show_graph(a,bds[i])\n",
        "#     show_graph(a)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZSyCLYIjrtMZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CVqU0RLjyBqk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class GraphConvolution(Module):\n",
        "    \"\"\"\n",
        "    Simple GCN layer, similar to https://arxiv.org/abs/1609.02907\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, in_features, out_features, bias=True):\n",
        "        super(GraphConvolution, self).__init__()\n",
        "        self.in_features = in_features\n",
        "        self.out_features = out_features\n",
        "        self.weight = Parameter(torch.FloatTensor(in_features, out_features))\n",
        "        if bias:\n",
        "            self.bias = Parameter(torch.FloatTensor(out_features))\n",
        "        else:\n",
        "            self.register_parameter('bias', None)\n",
        "        self.reset_parameters()\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        stdv = 1. / math.sqrt(self.weight.size(1))\n",
        "        self.weight.data.uniform_(-stdv, stdv)\n",
        "        if self.bias is not None:\n",
        "            self.bias.data.uniform_(-stdv, stdv)\n",
        "\n",
        "    def forward(self, input, adj):\n",
        "        support = torch.mm(input, self.weight)\n",
        "        output = torch.spmm(adj, support)\n",
        "        if self.bias is not None:\n",
        "            return output + self.bias\n",
        "        else:\n",
        "            return output\n",
        "\n",
        "    def __repr__(self):\n",
        "        return self.__class__.__name__ + ' (' \\\n",
        "               + str(self.in_features) + ' -> ' \\\n",
        "               + str(self.out_features) + ')'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U_IaeEU8yBqm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, av_size, d_size, gc_size, z_size, rep_size):\n",
        "        \"\"\"\n",
        "\n",
        "        :param av_size: D_A\n",
        "        :param d_size: D_X\n",
        "        :param gc_size: D'\n",
        "        :param z_size: z\n",
        "        \"\"\"\n",
        "        super(Encoder, self).__init__()\n",
        "        # input parameters\n",
        "        self.z_size = z_size\n",
        "        self.attr_vec = None\n",
        "        self.gc_size = gc_size\n",
        "        self.z_size = z_size\n",
        "        self.d_size = d_size\n",
        "        self.av_size = av_size\n",
        "        self.rep_size = rep_size\n",
        "        \n",
        "        self.gc = GraphConvolution(d_size + av_size, gc_size)\n",
        "        self.gc_mu = GraphConvolution(gc_size, z_size)\n",
        "        self.gc_logvar = GraphConvolution(gc_size, z_size)\n",
        "        \n",
        "        # self.mean = nn.Sequential( nn.Linear(gc_size, z_size))\n",
        "        # self.logvar = nn.Sequential(nn.Linear(gc_size, z_size)) \n",
        "        \n",
        "        self.mean = nn.Sequential(nn.Linear(self.gc_size, int(self.gc_size/4)), \n",
        "                                  nn.BatchNorm1d(int(self.gc_size/4)), \n",
        "                                  nn.ReLU(), \n",
        "                                  nn.Linear(int(self.gc_size/4), self.z_size))\n",
        "        \n",
        "        self.logvar = nn.Sequential(nn.Linear(self.gc_size, int(self.gc_size/4)), \n",
        "                                    nn.BatchNorm1d(int(self.gc_size/4)), \n",
        "                                    nn.ReLU(), \n",
        "                                    nn.Linear(int(self.gc_size/4), self.z_size))\n",
        "    def set_attr_vec(self, attr_vec):\n",
        "        self.attr_vec = attr_vec\n",
        "\n",
        "    def forward(self, adj):\n",
        "        # print('adj size',adj.size())\n",
        "        x = get_spectral_embedding(adj, d=self.d_size)\n",
        "        # print('Encoder, before mean logvar', x.size())\n",
        "        \n",
        "        adj = normalize(adj)\n",
        "        x = cat_attr(x, self.attr_vec)\n",
        "        # print('Before gc', 'x,size', x.size(),'att size',self.attr_vec.size()  , 'adj.size', adj.size())\n",
        "        x = F.relu(self.gc(x, adj))\n",
        "        x = F.dropout(x, p=0.5)\n",
        "        \n",
        "        # print('After gc')\n",
        "        #z_mean = self.gc_mu(x, adj)\n",
        "        #z_logvar = self.gc_logvar(x, adj)\n",
        "        \n",
        "        # create graph embedding N*D' -> 1*D'\n",
        "        # x = x.sum(0)\n",
        "        z_mean = self.mean(x)\n",
        "        z_logvar = self.logvar(x)\n",
        "        \n",
        "        # feature III here\n",
        "        # z_mean = torch.mean(z_mean, 0)\n",
        "        # z_mean = z_mean.repeat(z_logvar.shape[0], 1)\n",
        "\n",
        "        return z_mean, z_logvar"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FCC5u3soyBqo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Decoder(nn.Module):\n",
        "    def __init__(self, z_out_size, rep_size):\n",
        "        \"\"\"\n",
        "        :param z_out_size: = z_size + len(attr_vec)\n",
        "        \"\"\"\n",
        "        super(Decoder, self).__init__()\n",
        "        self.z_out_size = z_out_size\n",
        "        self.rep_size = rep_size\n",
        "        '''\n",
        "        self.decode = nn.Sequential(\n",
        "            nn.Linear(z_out_size, 32),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(32, 8),\n",
        "            nn.ReLU())\n",
        "        '''\n",
        "        self.decode = nn.Sequential(\n",
        "            #nn.Linear(z_out_size, self.rep_size),\n",
        "            #nn.BatchNorm1d(self.rep_size),\n",
        "            #nn.ReLU(),\n",
        "            nn.Linear(z_out_size, int(self.rep_size)),\n",
        "            nn.BatchNorm1d(int(self.rep_size)),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(int(self.rep_size), int(self.rep_size/4)),\n",
        "            #nn.BatchNorm1d(int(self.rep_size/2)),\n",
        "            #nn.ReLU()\n",
        "            )#nn.BatchNorm1d(int(self.rep_size/4)),\n",
        "\n",
        "        \n",
        "    def forward(self, z):\n",
        "        x = self.decode(z)\n",
        "        # x = z\n",
        "        x = torch.mm(x, x.t())\n",
        "        # x = F.sigmoid(x)\n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mk0YzQZXyBqq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Generator(nn.Module):\n",
        "    def __init__(self, av_size, d_size, gc_size, z_size, z_out_size, rep_size):\n",
        "        \"\"\"\n",
        "        :param av_size: D_A\n",
        "        :param d_size: D_X\n",
        "        :param gc_size: D' = GCN(D_X + D_A)\n",
        "        :param z_size: original z size\n",
        "        :param z_out_size: z size + D_A (append attribute)\n",
        "        \"\"\"\n",
        "        \n",
        "        super(Generator, self).__init__()\n",
        "        self.attr_vec = None\n",
        "        self.av_size = av_size\n",
        "        self.d_zize = d_size\n",
        "        self.z_size = z_size\n",
        "        self.z_out_size = z_out_size\n",
        "        self.rep_size = rep_size\n",
        "\n",
        "        self.encoder = Encoder(av_size, d_size, gc_size, z_size, rep_size)\n",
        "        self.decoder = Decoder(z_out_size,rep_size)\n",
        "    \n",
        "    def set_attr_vec(self, attr_vec):\n",
        "        self.attr_vec = attr_vec\n",
        "        self.encoder.set_attr_vec(attr_vec)\n",
        "   \n",
        "    def forward(self, adj, training=True):\n",
        "        # print('Before encoder')\n",
        "        mean, logvar = self.encoder(adj)\n",
        "        # print('After encoder')\n",
        "        if(training):\n",
        "            std = logvar.mul(0.5).exp_()\n",
        "            reparametrized_noise = torch.randn(mean.shape, requires_grad=True).cuda()\n",
        "            reparametrized_noise = mean + std * reparametrized_noise\n",
        "        else:\n",
        "            reparametrized_noise = mean\n",
        "            # print('mean',mean)\n",
        "        # print('After variational inference')\n",
        "        x = cat_attr(reparametrized_noise, self.attr_vec)\n",
        "        # print('Before decoder')\n",
        "        rec_x = self.decoder(x)\n",
        "        return mean, logvar, rec_x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "47J1pjWqyBqs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, av_size, d_size, gc_size, rep_size):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.av_size = av_size\n",
        "        self.attr_vec = None\n",
        "        self.d_size = d_size\n",
        "        self.gc_size = gc_size\n",
        "        self.rep_size = rep_size\n",
        "        self.gc = GraphConvolution(d_size + av_size, gc_size)\n",
        "        self.gc2 = GraphConvolution(gc_size, 8)\n",
        "        \n",
        "        self.main = nn.Sequential(\n",
        "            nn.Linear(gc_size, int(self.rep_size/2)),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Linear(int(self.rep_size/2), 8),\n",
        "            \n",
        "            nn.LeakyReLU(0.2))\n",
        "        \n",
        "            \n",
        "\n",
        "        self.sigmoid_output = nn.Sequential(\n",
        "            nn.Linear(8, 1),\n",
        "            nn.Sigmoid())\n",
        "    \n",
        "    def set_attr_vec(self, attr_vec):\n",
        "        self.attr_vec = attr_vec\n",
        "\n",
        "    def forward(self, adj):\n",
        "        # get spectral embedding from adj, D = D_X\n",
        "        x = get_spectral_embedding(adj, d=self.d_size)\n",
        "        adj = normalize(adj)\n",
        "        x = cat_attr(x, self.attr_vec)\n",
        "\n",
        "        # GCN layer N*D -> N*D'\n",
        "        x = F.relu(self.gc(x, adj))\n",
        "        # x = F.relu(self.gc2(x, adj))\n",
        "        # x = F.dropout(x, p=0.5)\n",
        "        x = self.main(x)\n",
        "        x = x.sum(0)\n",
        "        x = self.sigmoid_output(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "    def similarity(self, adj):\n",
        "        # get spectral embedding from adj, D = D_X\n",
        "        x = get_spectral_embedding(adj, d=self.d_size)\n",
        "        \n",
        "        # norm adj\n",
        "        adj = normalize(adj)\n",
        "\n",
        "        # concatenate attr mat, D = D_X + D_A\n",
        "        x = cat_attr(x, self.attr_vec)\n",
        "\n",
        "        # GCN layer N*D -> N*D'\n",
        "        x = F.relu(self.gc(x, adj))\n",
        "        # x = F.dropout(x, p=0.5)\n",
        "        # x = F.relu(self.gc2(x, adj))\n",
        "        # create graph embedding N*D' -> 1*D'\n",
        "        x = self.main(x)\n",
        "        x = x.mean(0)\n",
        "        # skip the last sigmoid layer\n",
        "        # x = self.main(x)\n",
        "        \n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0H4HQmyLhXRr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sample_adj(adj):\n",
        "    adj_sample = adj.data.cpu()\n",
        "    for i in range(adj.size(0)):\n",
        "        for j in range(adj.size(1)):\n",
        "            a = torch.bernoulli(adj.data[i, j])\n",
        "            adj_sample[i, j] = a\n",
        "    adj_sample = torch.min(adj_sample, adj_sample.t())\n",
        "    return adj_sample.cuda()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Grv2jmz_r48A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def top_n_indexes(arr, n):\n",
        "    idx = np.argpartition(arr, arr.size-n, axis=None)[-n:]\n",
        "    width = arr.shape[1]\n",
        "    return [divmod(i, width) for i in idx]\n",
        "\n",
        "# def topk_adj(adj, k):\n",
        "#     adj_ = adj.data.cpu().numpy()\n",
        "#     assert((adj_ == adj_.T).all())\n",
        "#     adj_ = (adj_-np.min(adj_)) / np.ptp(adj_)\n",
        "#     adj_ -= np.diag(np.diag(adj_))\n",
        "#     inds = top_n_indexes(adj_, k)\n",
        "#     res = torch.zeros(adj.shape)\n",
        "#     for ind in inds:\n",
        "#         res[ind] = 1.0\n",
        "#     return res.cuda()\n",
        "\n",
        "def topk_adj(adj, k):\n",
        "    adj_ = adj.data.cpu().numpy()\n",
        "    assert((adj_ == adj_.T).all())\n",
        "    adj_ = (adj_-np.min(adj_)) / np.ptp(adj_)\n",
        "    adj_ -= np.diag(np.diag(adj_))\n",
        "    tri_adj = np.triu(adj_)\n",
        "    inds = top_n_indexes(tri_adj, k // 2)\n",
        "    res = torch.zeros(adj.shape)\n",
        "    for ind in inds:\n",
        "        i = ind[0]\n",
        "        j = ind[1]\n",
        "        res[i, j] = 1.0\n",
        "        res[j, i] = 1.0\n",
        "    return res.cuda()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NB8SbJUoSiW_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test_gen(model, n, attr_vec, twice_edge_num, bd =None):\n",
        "    fixed_noise = torch.randn((n, z_size), requires_grad=True).cuda()\n",
        "    if attr_vec is not None:\n",
        "        fixed_noise = cat_attr(fixed_noise, attr_vec.cuda())\n",
        "    a_ = model.decoder(fixed_noise)\n",
        "    #print(F.sigmoid(a_))\n",
        "    a_ = topk_adj(F.sigmoid(a_), twice_edge_num)\n",
        "    #print(a_)\n",
        "    if bd:\n",
        "        show_graph(a_, bd)\n",
        "    else:\n",
        "        show_graph(a_)\n",
        "def gen_adj(model, n, e, attr_vec):\n",
        "    fixed_noise = torch.randn((n, z_size), requires_grad=True).cuda()\n",
        "    fixed_noise = cat_attr(fixed_noise, attr_vec)\n",
        "    rec_adj = model.decoder(fixed_noise)\n",
        "    return topk_adj(rec_adj, e*2)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7OdFeFLaIw5e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def eval(adj, base_adj=None):\n",
        "    if not isinstance(adj, np.ndarray):\n",
        "        adj_ = adj.data.cpu().numpy()\n",
        "    else:\n",
        "        adj_ = copy.deepcopy(adj)\n",
        "    \n",
        "    adj_ -= np.diag(np.diag(adj_))\n",
        "    gr = nx.from_numpy_array(adj_)\n",
        "    assert((adj_ == adj_.T).all())\n",
        "\n",
        "    d = compute_graph_statistics(adj_)\n",
        "    pprint(d)\n",
        "    \n",
        "    if base_adj is not None:\n",
        "        # base_adj = base_adj.numpy()\n",
        "        base_gr = nx.from_numpy_array(base_adj)\n",
        "        bd = compute_graph_statistics(base_adj)\n",
        "        diff_d = {}\n",
        "        \n",
        "        for k in list(d.keys()):\n",
        "            diff_d[k] = round(abs(d[k] - bd[k]), 4)\n",
        "    return diff_d\n",
        "\n",
        "\n",
        "def gen_adj(model, n, e, attr_vec):\n",
        "    fixed_noise = torch.randn((n, z_size), requires_grad=True).cuda()\n",
        "    fixed_noise = cat_attr(fixed_noise, attr_vec)\n",
        "    rec_adj = model.decoder(fixed_noise)\n",
        "    final_adj = topk_adj(rec_adj, e*2)\n",
        "    return final_adj\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "b9dfb921-7511-42fa-b8bc-e242bf04635c",
        "id": "-mpqNO2MFGgl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493
        }
      },
      "source": [
        "import random\n",
        "av_size = 10  # set 0 if you do not need attr_vec\n",
        "# d_size = 8\n",
        "#z_size = 64\n",
        "\n",
        "#gc_size = 16\n",
        "# d_size = 50\n",
        "# z_size = 16\n",
        "# gc_size = 32\n",
        "# rep_size = 32\n",
        "\n",
        "# z_size = 4\n",
        "# d_size = 16\n",
        "# gc_size = 16\n",
        "# rep_size = 32\n",
        "\n",
        "z_size = 6\n",
        "rep_size = 32\n",
        "d_size = 2\n",
        "gc_size = 16\n",
        "\n",
        "z_out_size = z_size + av_size\n",
        "\n",
        "adj_thresh = .6\n",
        "max_epochs = 30\n",
        "# lr = 3e-4\n",
        "lr = 0.003\n",
        "\n",
        "beta = 5\n",
        "beta2 = 0.1\n",
        "alpha = 0.1\n",
        "gamma = 15\n",
        "\n",
        "G = Generator(\n",
        "    av_size=av_size,\n",
        "    d_size=d_size,\n",
        "    gc_size=gc_size,\n",
        "    z_size=z_size,\n",
        "    z_out_size=z_out_size,\n",
        "    rep_size=rep_size\n",
        ").cuda()\n",
        "\n",
        "D = Discriminator(\n",
        "    av_size=av_size,\n",
        "    d_size=d_size,\n",
        "    gc_size=gc_size,\n",
        "    rep_size = rep_size\n",
        ").cuda()\n",
        "\n",
        "criterion_bce = nn.BCELoss()\n",
        "criterion_bce.cuda()\n",
        "\n",
        "# This three are for A A' loss\n",
        "loss_MSE = nn.MSELoss()\n",
        "loss_MSE.cuda()  \n",
        "\n",
        "loss_BCE_logits = nn.BCEWithLogitsLoss()#size_average=False)\n",
        "loss_BCE_logits.cuda()      \n",
        "\n",
        "loss_BCE = nn.BCELoss()#size_average=False)\n",
        "loss_BCE.cuda()     \n",
        "\n",
        "\n",
        "# opt_enc = optim.RMSprop(G.encoder.parameters(), lr=lr)\n",
        "# opt_dec = optim.RMSprop(G.decoder.parameters(), lr=lr)\n",
        "# opt_dis = optim.RMSprop(D.parameters(), lr=lr * alpha)\n",
        "\n",
        "\n",
        "opt_enc = optim.Adam(G.encoder.parameters(), lr=lr)\n",
        "opt_dec = optim.Adam(G.decoder.parameters(), lr=lr)\n",
        "opt_dis = optim.Adam(D.parameters(), lr=lr * alpha)\n",
        "\n",
        "\n",
        "# training_index = list(range(0, av_size))\n",
        "training_index = list(range(0, len(train_adj_mats)))\n",
        "\n",
        "\n",
        "for epoch in range(max_epochs):\n",
        "    D_real_list, D_rec_enc_list, D_rec_noise_list, D_list, Encoder_list = [], [], [], [], []\n",
        "    # g_loss_list, rec_loss_list, prior_loss_list = [], [], []\n",
        "    g_loss_list, rec_loss_list, prior_loss_list, aa_loss_list = [], [], [], []\n",
        "    random.shuffle(training_index)\n",
        "    for i in training_index:\n",
        "\n",
        "        ones_label = Variable(torch.ones(1)).cuda()\n",
        "        zeros_label = Variable(torch.zeros(1)).cuda()\n",
        "        # adj = Variable(train_adj_mats[i]).cuda()\n",
        "        adj = Variable(torch.from_numpy(train_adj_mats[i]).float()).cuda()\n",
        "        \n",
        "        #if adj.shape[0] <= d_size + 2 :\n",
        "        #    continue\n",
        "        if adj.shape[0] <= d_size + 2 or adj.shape[0]>=50:\n",
        "            continue   \n",
        "        if av_size == 0:\n",
        "            attr_vec = None\n",
        "        else:\n",
        "            #attr_vec = Variable(train_attr_vecs[i, :]).cuda()\n",
        "            attr_vec = Variable(torch.from_numpy(train_attr_vecs[i]).float()).cuda()\n",
        "            \n",
        "        # edge_num = train_adj_mats[i].sum()\n",
        "        G.set_attr_vec(attr_vec)\n",
        "        D.set_attr_vec(attr_vec)\n",
        "        \n",
        "        norm = adj.shape[0] * adj.shape[0] / float((adj.shape[0] * adj.shape[0] - adj.sum()) * 2)\n",
        "        pos_weight = float(adj.shape[0] * adj.shape[0] - adj.sum()) / adj.sum()\n",
        "        # print('pos_weight', pos_weight)\n",
        "        \n",
        "        mean, logvar, rec_adj = G(adj)\n",
        "        \n",
        "        noisev = torch.randn(mean.shape, requires_grad=True).cuda()\n",
        "        noisev = cat_attr(noisev, attr_vec)\n",
        "        rec_noise = G.decoder(noisev)\n",
        "        \n",
        "        \n",
        "        e = int(np.sum(train_adj_mats[i])) // 2\n",
        "        \n",
        "        c_adj = topk_adj(F.sigmoid(rec_adj), e*2)\n",
        "        c_noise = topk_adj(F.sigmoid(rec_noise), e*2)\n",
        "\n",
        "        \n",
        "        # train discriminator\n",
        "        output = D(adj)\n",
        "        errD_real = criterion_bce(output, ones_label)\n",
        "        D_real_list.append(output.data.mean())\n",
        "        #output = D(rec_adj)\n",
        "        output = D(c_adj)\n",
        "        errD_rec_enc = criterion_bce(output, zeros_label)\n",
        "        D_rec_enc_list.append(output.data.mean())\n",
        "        # output = D(rec_noise)\n",
        "        output = D(c_noise)\n",
        "       \n",
        "        errD_rec_noise = criterion_bce(output, zeros_label)\n",
        "        D_rec_noise_list.append(output.data.mean())\n",
        "        \n",
        "        dis_img_loss = errD_real + errD_rec_enc + errD_rec_noise\n",
        "        # print (\"print (dis_img_loss)\", dis_img_loss)\n",
        "        D_list.append(dis_img_loss.data.mean())\n",
        "        opt_dis.zero_grad()\n",
        "        dis_img_loss.backward(retain_graph=True)\n",
        "        opt_dis.step()\n",
        "        \n",
        "        \n",
        "        # AA_loss b/w rec_adj and adj\n",
        "        # aa_loss = loss_MSE(rec_adj, adj)\n",
        "        \n",
        "        loss_BCE_logits = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
        "        loss_BCE_logits.cuda()\n",
        "        \n",
        "        aa_loss = loss_BCE_logits(rec_adj, adj)\n",
        "       \n",
        "        #print(c_adj,c_adj)\n",
        "        #aa_loss = loss_BCE(c_adj, adj)\n",
        "        \n",
        "        # train decoder\n",
        "        output = D(adj)\n",
        "        errD_real = criterion_bce(output, ones_label)\n",
        "        # output = D(rec_adj)\n",
        "        output = D(c_adj)\n",
        "            \n",
        "        errD_rec_enc = criterion_bce(output, zeros_label)\n",
        "        errG_rec_enc = criterion_bce(output, ones_label)\n",
        "        # output = D(rec_noise)\n",
        "        output = D(c_noise)\n",
        "        \n",
        "        errD_rec_noise = criterion_bce(output, zeros_label)\n",
        "        errG_rec_noise = criterion_bce(output, ones_label)\n",
        "        \n",
        "        similarity_rec_enc = D.similarity(c_adj)\n",
        "        similarity_data = D.similarity(adj)\n",
        "        \n",
        "        dis_img_loss = errD_real + errD_rec_enc + errD_rec_noise \n",
        "        # print (dis_img_loss)\n",
        "        \n",
        "        \n",
        "        # gen_img_loss = norm*(aa_loss + errG_rec_enc  + errG_rec_noise)- dis_img_loss #- dis_img_loss #aa_loss #+ errG_rec_enc  + errG_rec_noise # - dis_img_loss \n",
        "        gen_img_loss = - dis_img_loss #norm*(aa_loss) #\n",
        "        \n",
        "        g_loss_list.append(gen_img_loss.data.mean())\n",
        "        rec_loss = ((similarity_rec_enc - similarity_data) ** 2).mean()\n",
        "        rec_loss_list.append(rec_loss.data.mean())\n",
        "        # err_dec =  gamma * rec_loss + gen_img_loss\n",
        "        \n",
        "        err_dec =  gamma * rec_loss + gen_img_loss\n",
        "        opt_dec.zero_grad()\n",
        "        err_dec.backward(retain_graph=True)\n",
        "        opt_dec.step()\n",
        "        \n",
        "        # train encoder\n",
        "        # fix me: sum version of prior loss\n",
        "        pl = []\n",
        "        for j in range(mean.size()[0]):\n",
        "            prior_loss = 1 + logvar[j, :] - mean[j, :].pow(2) - logvar[j, :].exp()\n",
        "            prior_loss = (-0.5 * torch.sum(prior_loss))/torch.numel(mean[j, :].data)\n",
        "            pl.append(prior_loss)\n",
        "        prior_loss_list.append(sum(pl))\n",
        "        err_enc = sum(pl) + gen_img_loss + beta * (rec_loss ) #+ beta2* norm* aa_loss\n",
        "        opt_enc.zero_grad()\n",
        "        err_enc.backward()\n",
        "        opt_enc.step()\n",
        "        Encoder_list.append(err_enc.data.mean())\n",
        "         \n",
        "    print('[%d/%d]: D_real:%.4f, D_enc:%.4f, D_noise:%.4f, Loss_D:%.4f, Loss_G:%.4f, rec_loss:%.4f, prior_loss:%.4f' \n",
        "                   % (epoch, \n",
        "                      max_epochs, \n",
        "                      torch.mean(torch.stack(D_real_list)), \n",
        "                      torch.mean(torch.stack(D_rec_enc_list)), \n",
        "                      torch.mean(torch.stack(D_rec_noise_list)), \n",
        "                      torch.mean(torch.stack(D_list)), \n",
        "                      torch.mean(torch.stack(g_loss_list)),\n",
        "                      torch.mean(torch.stack(rec_loss_list)),\n",
        "                      torch.mean(torch.stack(prior_loss_list))))\n",
        "    '''\n",
        "    print('Training set')\n",
        "    for i in range(3):\n",
        "        base_adj = train_adj_mats[i]\n",
        "        \n",
        "        if base_adj.shape[0] <= d_size:\n",
        "            continue\n",
        "        print('Base Adj_size: ',base_adj.shape)\n",
        "        attr_vec = Variable(torch.from_numpy(train_attr_vecs[i]).float()).cuda()\n",
        "\n",
        "        # add a new line\n",
        "        G.set_attr_vec(attr_vec)\n",
        "\n",
        "        print('Show sample')\n",
        "        sample_adj = gen_adj(G, base_adj.shape[0], int(np.sum(base_adj)) // 2, attr_vec)\n",
        "        show_graph(sample_adj, base_adj=base_adj, remove_isolated=True)\n",
        "    '''"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0/30]: D_real:0.4955, D_enc:0.5100, D_noise:0.4977, Loss_D:2.2376, Loss_G:-2.2094, rec_loss:0.0006, prior_loss:1.3851\n",
            "[1/30]: D_real:0.4089, D_enc:0.4201, D_noise:0.4239, Loss_D:2.1881, Loss_G:-2.1817, rec_loss:0.0005, prior_loss:0.8530\n",
            "[2/30]: D_real:0.4392, D_enc:0.4382, D_noise:0.4384, Loss_D:2.1163, Loss_G:-2.1313, rec_loss:0.0005, prior_loss:0.5531\n",
            "[3/30]: D_real:0.4162, D_enc:0.4139, D_noise:0.4217, Loss_D:2.0794, Loss_G:-2.0922, rec_loss:0.0005, prior_loss:0.3583\n",
            "[4/30]: D_real:0.4131, D_enc:0.4130, D_noise:0.4125, Loss_D:2.0546, Loss_G:-2.0356, rec_loss:0.0007, prior_loss:0.2411\n",
            "[5/30]: D_real:0.4171, D_enc:0.4184, D_noise:0.4237, Loss_D:2.0595, Loss_G:-2.0266, rec_loss:0.0006, prior_loss:0.1658\n",
            "[6/30]: D_real:0.4140, D_enc:0.4091, D_noise:0.4117, Loss_D:2.0225, Loss_G:-1.9787, rec_loss:0.0006, prior_loss:0.1039\n",
            "[7/30]: D_real:0.4069, D_enc:0.3974, D_noise:0.3911, Loss_D:1.9749, Loss_G:-1.9486, rec_loss:0.0005, prior_loss:0.0506\n",
            "[8/30]: D_real:0.4055, D_enc:0.3906, D_noise:0.3819, Loss_D:1.9428, Loss_G:-1.9290, rec_loss:0.0004, prior_loss:0.0219\n",
            "[9/30]: D_real:0.4321, D_enc:0.4078, D_noise:0.4073, Loss_D:1.9309, Loss_G:-1.9549, rec_loss:0.0004, prior_loss:0.0096\n",
            "[10/30]: D_real:0.4312, D_enc:0.4033, D_noise:0.3919, Loss_D:1.8942, Loss_G:-1.8626, rec_loss:0.0003, prior_loss:0.0053\n",
            "[11/30]: D_real:0.4096, D_enc:0.3689, D_noise:0.3772, Loss_D:1.8774, Loss_G:-1.8744, rec_loss:0.0005, prior_loss:0.0043\n",
            "[12/30]: D_real:0.4202, D_enc:0.3724, D_noise:0.3746, Loss_D:1.8511, Loss_G:-1.8563, rec_loss:0.0005, prior_loss:0.0037\n",
            "[13/30]: D_real:0.4206, D_enc:0.3848, D_noise:0.3796, Loss_D:1.8650, Loss_G:-1.8578, rec_loss:0.0005, prior_loss:0.0028\n",
            "[14/30]: D_real:0.4174, D_enc:0.3668, D_noise:0.3636, Loss_D:1.8253, Loss_G:-1.8282, rec_loss:0.0005, prior_loss:0.0026\n",
            "[15/30]: D_real:0.4179, D_enc:0.3718, D_noise:0.3597, Loss_D:1.8256, Loss_G:-1.8437, rec_loss:0.0006, prior_loss:0.0023\n",
            "[16/30]: D_real:0.4303, D_enc:0.3841, D_noise:0.3759, Loss_D:1.8493, Loss_G:-1.8027, rec_loss:0.0005, prior_loss:0.0017\n",
            "[17/30]: D_real:0.4189, D_enc:0.3618, D_noise:0.3580, Loss_D:1.7978, Loss_G:-1.7832, rec_loss:0.0004, prior_loss:0.0018\n",
            "[18/30]: D_real:0.4160, D_enc:0.3568, D_noise:0.3538, Loss_D:1.7994, Loss_G:-1.7696, rec_loss:0.0005, prior_loss:0.0015\n",
            "[19/30]: D_real:0.4201, D_enc:0.3583, D_noise:0.3623, Loss_D:1.7996, Loss_G:-1.7889, rec_loss:0.0005, prior_loss:0.0013\n",
            "[20/30]: D_real:0.4191, D_enc:0.3473, D_noise:0.3525, Loss_D:1.7701, Loss_G:-1.8012, rec_loss:0.0007, prior_loss:0.0014\n",
            "[21/30]: D_real:0.4020, D_enc:0.3322, D_noise:0.3364, Loss_D:1.7696, Loss_G:-1.7811, rec_loss:0.0005, prior_loss:0.0013\n",
            "[22/30]: D_real:0.4282, D_enc:0.3602, D_noise:0.3580, Loss_D:1.7780, Loss_G:-1.7788, rec_loss:0.0004, prior_loss:0.0014\n",
            "[23/30]: D_real:0.4209, D_enc:0.3444, D_noise:0.3287, Loss_D:1.7216, Loss_G:-1.7493, rec_loss:0.0006, prior_loss:0.0009\n",
            "[24/30]: D_real:0.4305, D_enc:0.3533, D_noise:0.3385, Loss_D:1.7412, Loss_G:-1.7343, rec_loss:0.0006, prior_loss:0.0008\n",
            "[25/30]: D_real:0.3995, D_enc:0.3291, D_noise:0.3248, Loss_D:1.7469, Loss_G:-1.7098, rec_loss:0.0008, prior_loss:0.0011\n",
            "[26/30]: D_real:0.4169, D_enc:0.3415, D_noise:0.3291, Loss_D:1.7402, Loss_G:-1.7146, rec_loss:0.0006, prior_loss:0.0010\n",
            "[27/30]: D_real:0.4287, D_enc:0.3441, D_noise:0.3228, Loss_D:1.6987, Loss_G:-1.7284, rec_loss:0.0007, prior_loss:0.0007\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZJNh8qxGokgU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#### EVAL\n",
        "# Evaluation\n",
        "import math\n",
        "\n",
        "diffs ={}\n",
        "for i in range(len(train_adj_mats)):\n",
        "    print('Graph %d'%i)\n",
        "    base_adj = train_adj_mats[i] #Variable(torch.from_numpy(train_adj_mats[i]).float()).cuda()\n",
        "        \n",
        "    if base_adj.shape[0] <= d_size + 2 or base_adj.shape[0] >=50:\n",
        "            continue\n",
        "            \n",
        "    # attr_vec = Variable(train_attr_vecs[i].float()).cuda()\n",
        "    attr_vec = Variable(torch.from_numpy(train_attr_vecs[i]).float()).cuda()\n",
        "    \n",
        "    # add a new line\n",
        "    G.set_attr_vec(attr_vec)\n",
        "    for u in range(3):\n",
        "        sample_adj = gen_adj(G, base_adj.shape[0], int((base_adj).sum()) // 2, attr_vec)\n",
        "        diff_d = eval(sample_adj, base_adj=base_adj)\n",
        "        if math.isnan(diff_d['cpl']):\n",
        "            continue\n",
        "        for k in list(diff_d.keys()):\n",
        "            if k not in diffs.keys():\n",
        "                diffs[k] = []\n",
        "            diffs[k].append(diff_d[k])\n",
        "            \n",
        "for k in list(diffs.keys()):  \n",
        "    diffs[k] = np.mean(diffs[k])    \n",
        "print(diffs)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-MAG8Wd6r_a2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(diffs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0g-liHF1a749",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "  \n",
        "for id_ in range(13):\n",
        "    for _ in range(6):\n",
        "        if(id_ == 7 or id_ == 10 ):\n",
        "            \n",
        "            print('Graph %d'%id_) \n",
        "            test_gen(G, train_adj_mats[id_].size()[0], t_attr_vecs[id_,:], twice_edge_num =int(train_adj_mats[id_].sum().numpy()))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "li9V2Eb5vhxq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Implement VAE-GAN Here to check the results\n",
        "\n",
        "av_size = 0  # set 0 if you do not need attr_vec\n",
        "# d_size = 8\n",
        "#z_size = 64\n",
        "#gc_size = 16\n",
        "d_size = 50 #16\n",
        "z_size = 32\n",
        "gc_size = 16\n",
        "rep_size = 16\n",
        "z_out_size = z_size + av_size\n",
        "\n",
        "adj_thresh = .5\n",
        "max_epochs = 2000\n",
        "lr = 0.001\n",
        "\n",
        "\n",
        "beta = 5\n",
        "alpha = 0.1\n",
        "gamma = 15\n",
        "\n",
        "G = Generator(\n",
        "    av_size=av_size,\n",
        "    d_size=d_size,\n",
        "    gc_size=gc_size,\n",
        "    z_size=z_size,\n",
        "    z_out_size=z_out_size,\n",
        "    rep_size=rep_size\n",
        ").cuda()\n",
        "'''\n",
        "D = Discriminator(\n",
        "    av_size=av_size,\n",
        "    d_size=d_size,\n",
        "    gc_size=gc_size\n",
        ").cuda()\n",
        "'''\n",
        "criterion_bce = nn.BCELoss()\n",
        "criterion_bce.cuda()\n",
        "\n",
        "loss_MSE = nn.MSELoss()\n",
        "loss_MSE.cuda()   \n",
        "loss_BCE = nn.BCELoss()\n",
        "loss_BCE.cuda()      \n",
        "  \n",
        "for name, param in G.named_parameters():\n",
        "\tprint(name, '      ', param.size())\n",
        "# I won't use the next 3 lines\n",
        "opt_enc = optim.RMSprop(G.encoder.parameters(), lr=lr)\n",
        "opt_dec = optim.RMSprop(G.decoder.parameters(), lr=lr)\n",
        "#opt_dis = optim.RMSprop(D.parameters(), lr=lr * alpha)\n",
        "\n",
        "#opt_vae = optim.RMSprop(G.parameters(), lr=lr)\n",
        "opt_vae = optim.Adam(G.parameters(), lr=lr)\n",
        "\n",
        "\n",
        "training_index = list(range(0, av_size))\n",
        "\n",
        "# Empty graphs\n",
        "training_index.remove(9)\n",
        "training_index.remove(12)\n",
        "\n",
        "for epoch in range(max_epochs):\n",
        "    D_real_list, D_rec_enc_list, D_rec_noise_list, D_list = [], [], [], []\n",
        "    # g_loss_list, rec_loss_list, prior_loss_list = [], [], []\n",
        "    g_loss_list, rec_loss_list, prior_loss_list, aa_loss_list = [], [], [], []\n",
        "    # for i in range(len(train_adj_mats)):\n",
        "    \n",
        "    random.shuffle(training_index)\n",
        "    for i in training_index:\n",
        "        ones_label = Variable(torch.ones(1)).cuda()\n",
        "        zeros_label = Variable(torch.zeros(1)).cuda()\n",
        "        edge_num = train_adj_mats[i].sum()\n",
        "        adj = Variable(train_adj_mats[i]).cuda()\n",
        "        if adj.shape[0] <= d_size:\n",
        "            continue\n",
        "            \n",
        "        if av_size == 0:\n",
        "            attr_vec = None\n",
        "        else:\n",
        "            attr_vec = Variable(t_attr_vecs[i, :]).cuda()\n",
        "        \n",
        "        G.set_attr_vec(attr_vec)\n",
        "        D.set_attr_vec(attr_vec)\n",
        "        \n",
        "        norm = adj.shape[0] * adj.shape[0] / float((adj.shape[0] * adj.shape[0] - adj.sum()) * 2)\n",
        "        pos_weight = float(adj.shape[0] * adj.shape[0] - adj.sum()) / adj.sum()\n",
        "        # print('pos_weight', pos_weight)\n",
        "        mean, logvar, rec_adj = G(adj, training=True)\n",
        "        \n",
        "        noisev = torch.randn(mean.shape, requires_grad=True).cuda()\n",
        "        noisev = cat_attr(noisev, attr_vec)\n",
        "        rec_noise = G.decoder(noisev)\n",
        "        '''\n",
        "        # train discriminator\n",
        "        output = D(adj)\n",
        "        errD_real = criterion_bce(output, ones_label)\n",
        "        D_real_list.append(output.data.mean())\n",
        "        output = D(rec_adj)\n",
        "        errD_rec_enc = criterion_bce(output, zeros_label)\n",
        "        D_rec_enc_list.append(output.data.mean())\n",
        "        output = D(rec_noise)\n",
        "        errD_rec_noise = criterion_bce(output, zeros_label)\n",
        "        D_rec_noise_list.append(output.data.mean())\n",
        "        \n",
        "        dis_img_loss = errD_real + errD_rec_enc + errD_rec_noise\n",
        "        # print (\"print (dis_img_loss)\", dis_img_loss)\n",
        "        D_list.append(dis_img_loss.data.mean())\n",
        "        opt_dis.zero_grad()\n",
        "        dis_img_loss.backward(retain_graph=True)\n",
        "        opt_dis.step()\n",
        "        \n",
        "        loss_BCE_logits = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
        "        loss_BCE_logits.cuda() \n",
        "        \n",
        "        # AA_loss b/w rec_adj and adj\n",
        "        # aa_loss = loss_MSE(rec_adj, adj)\n",
        "        # aa_loss = loss_BCE_logits(rec_adj, adj)\n",
        "        #b_adj=F.sigmoid(rec_adj)\n",
        "        #b_adj[F.sigmoid(rec_adj)<=0.6] =0\n",
        "        #c_adj = sample_adj(b_adj)\n",
        "        \n",
        "        c_adj = topk_adj(F.sigmoid(rec_adj), int(edge_num.numpy()))\n",
        "        aa_loss = loss_BCE(c_adj, adj)\n",
        "        \n",
        "        # fix me: sum version of prior loss\n",
        "        pl = []\n",
        "        for i in range(mean.size()[0]):\n",
        "            prior_loss = 1 + logvar[i, :] - mean[i, :].pow(2) - logvar[i, :].exp()\n",
        "            prior_loss = (-0.5 * torch.sum(prior_loss))/torch.numel(mean[i, :].data)\n",
        "            pl.append(prior_loss)\n",
        "        prior_loss_list.append(sum(pl))\n",
        "        kl_loss = sum(pl)/torch.numel(mean[i, :].data)\n",
        "        vae_loss = kl_loss + norm*aa_loss\n",
        "        opt_vae.zero_grad()\n",
        "        vae_loss.backward() #retain_graph=True\n",
        "        opt_vae.step()\n",
        "        \n",
        "    if epoch % 30 == 0:   \n",
        "        _,_, rec_adj = G(adj, training=False)\n",
        "        b_adj = F.sigmoid(rec_adj)\n",
        "        b_adj[F.sigmoid(rec_adj)<=0.5] =0\n",
        "        c_adj = sample_adj(b_adj)\n",
        "        \n",
        "        print('[%d/%d]: vae_loss:%.4f, prior_loss:%.4f' \n",
        "               % (epoch, \n",
        "                  max_epochs, \n",
        "                  torch.mean(torch.stack([vae_loss])),\n",
        "                  torch.mean(torch.stack(prior_loss_list))))\n",
        "\n",
        "        print('max',(rec_adj.max()),'min',(rec_adj.min()))\n",
        "       \n",
        "        print('rec_adj w/ sigmoid', F.sigmoid(rec_adj))\n",
        "        #148\n",
        "        # print(edge_num.numpy(),'edge_num')\n",
        "        show_graph(topk_adj(F.sigmoid(rec_adj), int(edge_num.numpy()) ), thresh=adj_thresh)\n",
        "        show_graph(topk_adj(c_adj, int(edge_num.numpy())), thresh=0)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u9O69OwY5AcT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(G)\n",
        "print(D)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}